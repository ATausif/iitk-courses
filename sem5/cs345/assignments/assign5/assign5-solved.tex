\documentclass{article}

\usepackage{assign}

\setcoursetitle{CS345: Algorithms II}
\setauthname{Gurpreet Singh and Nikita Awasthi}
\setauthroll{150259 and 150453}
\setheaddate{15 November, 2017}
\setassigncode{5}

\begin{document}
\makeheader%
%\setstartnewpage{TRUE}

\begin{question}

    For implementing the structure described in the question, we have used two arrays. One array will store the values of the elements in the set in a sorted manner (increasing order of value). We can always visualize a sorted array as a weight balanced BST, with the middle element as the root pointing to the middle element of the left half, and the middle element of the right half, and so on. \br%

    The second array will be used as a translation from the linear array into this structure. Each element will store the size of the subtree formed at that element \et{i.e.} the middle element will store $n$, the length of the array, the middle element of the left half will store $\approx n/2$, and so on.

    \begin{qsubsection}{Explanation}

        If we assume that we can succesfully simulate a weight Balanced Binary Tree using two arrays, and solve the problem using a single BST, the visualization becomes easier. \br%

        The basic idea is that we do not delete an element when called upon, but delete lazily. That is, we delete the elements all together, when the total number of elements deleted are half of that of the size of the BST. \br%

        Consider the idea of deleting in a normal Balanced BST, such as a Red Black Tree. The procedure is to first replace the element with a leaf node, that does not harm the sorted nature of the BST, and then delete the element. We follow the same procedure, \et{i.e.} We replace the element with a valid leaf node. However, instead of deleting the element, we simply let it be, however, we invalidate the value, \et{i.e.} we mark it as deleted. \br%

        \note{We consider any element with only deleted elements as its child nodes as a leaf node too, however, the second array \tt{sizes} will not change on deletion of an element}

        While finding the valid leaf node, we must make sure that the leaf node itself has not been deleted. For searching and predecessor problems, we function exactly as we would in a normal Binary Search Tree. \br%

        The idea is very similar to pruning a tree, but by marking the lower level nodes.

    \end{qsubsection}

    \begin{qsection}{Algorithm}

        \begin{qsubsection}{Pseudocode}

            \begin{algo}[0.9\textwidth]{h!}{Initialization of Arrays and Functions for Recreating / Reordering the Arrays}
                \begin{algorithmic}
                    \State{elements $\gets$ \Call{SortedArray}{S}}            \Comment{Array of values of elements in sorted manner}
                    \State{sizes $\gets$ \Call{Array}{0, 0 \ldots\ 0}}        \Comment{Array of 0s for size of subtrees at elements}
                    \sbr%
                    \State{\Call{computeSizes}{sizes, sizes}}
                    \State{numElements $\gets$ \Call{size}{S}}
                    \\
                    \Procedure{computeSizes}{sizes}
                    \State{len $\gets$ sizes.length}
                    \sbr%
                    \If{len $\le$ 1}
                        \State{sizes[0] = len}
                    \EndIf%
                    \sbr%
                    \State{sizes[len / 2] $\gets$ len}
                    \sbr%
                    \State{\Call{computeSizes}{sizes[0 \ldots\ len / 2 - 1], sizes}}
                    \State{\Call{computeSizes}{sizes[len / 2 + 1 \ldots\ len], sizes}}
                    \sbr%
                    \EndProcedure
                    \\
                    \Procedure{recomputeArrays}{size}
                        \State{newElements $\gets$ \Call{Array}{size}}
                        \sbr%
                        \State{count $\gets$ 0}
                        \For{i in $\set{0 \ldots \para{\text{elements.length} - 1}}$}
                            \sbr%
                            \If{elements[i] $\ne$ NULL}
                                \State{newElements[count] $\gets$ elements[i]}
                                \State{count $\gets$ count + 1}
                            \EndIf%
                            \sbr%
                        \EndFor%
                        \sbr%
                        \State{delete elements}
                        \State{delete sizes}
                        \sbr%
                        \State{elements $\gets$ newElements}
                        \State{sizes $\gets$ \Call{Array}{$\set{0, 0 \ldots\ 0}$, size}}                \Comment{Array of `size' 0s}
                        \sbr%
                        \State{\Call{computeSizes}{sizes}{sizes}}
                        \sbr%
                    \EndProcedure%
                \end{algorithmic}
            \end{algo}

            \begin{algo}[0.9\textwidth]{h!}{Search and Predecessor Functions}
                \begin{algorithmic}
                    \Procedure{search}{key}
                        \State{start $\gets$ 0, \quad end $\gets$ elements.length - 1}
                        \sbr%
                        \While{start $\ne$ end}
                            \sbr%
                            \State{mid $\gets$ (start + end) / 2}       \Comment{Integer Division with Round Down}
                            \sbr%
                            \If{elements[mid] $=$ NULL}
                                \State{\Return{NULL}}
                            \EndIf
                            \sbr%
                            \If{elements[mid] $>$ key}
                                \State{end $\gets$ mid}
                            \ElsIf{elements[mid] $<$ key}
                                \State{start $\gets$ mid + 1}
                            \Else%
                                \State{\Return{mid}}
                            \EndIf%
                            \sbr%
                        \EndWhile%
                        \sbr%
                        \State{\Return{start}}
                        \sbr%
                    \EndProcedure%
                    \\
                    \Procedure{predecessor}{key}
                        \State{pred $\gets$ NULL}
                        \State{index $\gets$ elements.length / 2}
                        \sbr%
                        \While{elements[index] $\ne$ NULL \bt{and} sizes[index] $\ne$ 1}
                            \sbr%
                            \If{elements[index] $<$ key}
                                \State{pred $\gets$ index}
                                \State{index $\gets$ index + (sizes[index] - 1) / 2 + 1}
                            \Else%
                                \State{index $\gets$ index - sizes[index] / 2 - 1}
                            \EndIf%
                            \sbr%
                        \EndWhile%
                        \sbr%
                        \State{\Return{pred}}
                        \sbr%
                    \EndProcedure%
                \end{algorithmic}
            \end{algo}

            \begin{algo}[0.9\textwidth]{h!}{Delete Function}
                \begin{algorithmic}
                    \Procedure{left}{index}
                    \State{\Return{index - (sizes[index] / 2 - 1) / 2 - 1}}
                    \EndProcedure
                    \\
                    \Procedure{right}{index}
						\If{sizes[index] $\le$ 2}
							\State{\Return{index}}
						\EndIf
						\sbr%
                        \State{\Return{index + (sizes[index] - 1) / 4 + 1}}
                    \EndProcedure
                    \\
                    \Procedure{delete}{key}
                        \State{index $\gets$ \Call{search}{key}}
                        \If{index $=$ NULL}
                            \State{\Return{}}
                        \EndIf
                        \sbr%
                        \\
                        \sbr%
                        \ \ \ \et{\#\# Standard Code for Replacing with a leaf node (except using arrays)}
                        \sbr%
                        \State{replacement $\gets$ NULL}
                        \snr%
                        \While{\Call{left}{index} $\ne$ index \bt{and} elements[\Call{left}{index}] $\ne$ NULL}
                            \While{right[replacement] $\ne$ replacement}
                                \State{replacement $\gets$ right[replacement]}
                            \EndWhile
                            \sbr%
                            \State{\Call{switchValues}{index, replacement}}					\Comment{Exchange values at the indices}
                            \State{index $\gets$ replacement}
                        \EndWhile
                        \sbr%
                        \If{replacement $=$ NULL}
                            \While{\Call{right}{index} $\ne$ index \bt{and} elements[\Call{right}{index}] $\ne$ NULL}
                                \While{left[replacement] $\ne$ replacement}
                                    \State{replacement $\gets$ left[replacement]}
                                \EndWhile
                                \sbr%
                                \State{\Call{switchValues}{index, replacement}}
                                \State{index $\gets$ replacement}
                            \EndWhile
                        \EndIf
                        \sbr%
                        \State{elements[index] $\gets$ NULL}
                        \sbr%
                        \State{numElements $\gets$ numElements - 1}
                        \If{numElements $=$ elements.length / 2}
                            \State{\Call{recomputeArrays}{numElements}}
                            \State{\Return{}}
                        \EndIf
                        \sbr%
                    \EndProcedure
                \end{algorithmic}
            \end{algo}

        \end{qsubsection}
    \end{qsection}

    \clearpage

    \begin{qsection}{Time Complexity Analysis}

        For \st{search} operation, we are using a simple binary search on the sorted array of elements which has worst case $\bigO{\log{n}}$ bound. \br%

        For the \st{predecessor} function, since we are maintaining a balanced binary search tree using a sorted array of elements and an array maintaining the size of the subtree rooted atsevery node which gives us an $\bigO{1}$ worst case bound to access the left and right child of any given element. The height of the simulated tree therefore sis $\bigO{\log{n}}$. Since the height bound and $\bigO{1}$ access to left and right child ensures simulation of balanced search tree, we get predecessor of an element in $\bigO{\log{n}}$. \br%

        For the case of deletion, since we are reordering when the number of elements deleted is equal to atmost half the number of elements present in the array. Therefore on reordering the height of the tree is bounded by $\bigO{\log{\frac{n}{2}}}$ which is $\bigO{\log{n}}$. Also, since we have simulated a balanced binary search tree with access to left and right children through \st{left} and \st{right} functions. Therefore, we can replace a deleted node with a leaf node in $\bigO{\log{\frac{n}{2}}}$ as the height of the tree is $\bigO{\log{n}}$.

        \begin{qsubsection}{Amortized Analysis of Deletion Operation}

            The potential function we will use for this case is the difference between the number of valid elements in the elements array and the total size of the elements array. In terms of the pseudocode, this can be defined as $\phi = c_3 \para{elements.length - numElements}$. \br%

            \note{$c$ is just a positive constant multiplied to allow the proper use of the potential function} \br%

            \note{Valid element is an element that has not been deleted, since all the elements deleted are not instantly removed from the array} \br%

            \begin{qproof}{$\phi$ is a valid potential function}

                Initially, the size of the elements array is $\abs{S}$ and so is the number of valid elements. Hence, initially, $numElements = elements.length \implies \phi = 0$ \br%

                At any time, the length of the array is greater than the number of valid elements as we are never inserting elements. Therefore, $elements.length \ge numElements \implies \phi \ge 0$. \br%

                Therefore, our potential function satisfies the properties of potential functions, and is thus valid.

            \end{qproof}

            For the actual cost, we will have to find the index of the element we require to delete. This is $\bigO{\log{n}}$. When the number of deletions are less than half the number of elements present, the node is marked as NULL which is $\bigO{1}$ and then it is replaced with a leaf node. \br%

			Since the height of the simulated tree is bounded by $\bigO{\log{n}}$, the length of the path from the node to the leaf node would be atmost $\log{n}$. Therefore, this part would take $\bigO{\log{n}}$ \br%

            \note{We set $c = 2 c_3$}

            \begin{table}[h!]
                \centering
                \begin{tabular}{| X{5cm} | X{3cm} | X{3cm} | X{3cm} |}
                    \hline
                    \bt{Case}   &   \bt{Actual Cost}    &   $\bm{\Delta \phi}$  &   \bt{Amortized Cost} \\
                    \hline
                    When number of valid elements is greater than half the length of the elements array &   $c_1 \log{n} + c_2$ &   $c \para{-1}$   &   $c_1 \log{n} + c_2 - 2 c_3$ \\
                    \hline
                    When number of valid elements is equal to one more than the length of the elements array    &   $c_1 \log{n} + \pr{c_3} n + \pr{c_4}$   &   $c \para{- \frac{n}{2}}$    &   $c_1 \log{n} + c_4$ \\
                    \hline
                \end{tabular}
            \end{table}

            Hence, the amortized cost for the deletion operation is $\bigO{\log{n}}$. Therefore, our algorithm works in the required constraints.

        \end{qsubsection}

    \end{qsection}

\end{question}

\begin{question}

    \begin{qsection}{Algorithm}

        \begin{algo}[0.9\textwidth]{h!}{Completed Update-R Function}
            \begin{algorithmic}
                \Procedure{Update-R}{i, j}
                    \If{R[i] = true \bt{and} R[j] = false}
                        \State{R[j] $\gets$ true}
                        \For{neighbours of j as q}
                            \State{\Call{Update-R}{j, q}}
                        \EndFor%
                    \EndIf%
                \EndProcedure%
            \end{algorithmic}
        \end{algo}

    \end{qsection}

    \begin{qsection}{Amortized Analysis}

        \begin{qsubsection}{Notations}

            We will call each vertex that is unreachable from the source vertex as marked. Therefore, in every insertion of any edge, it is possible that some of the vertices get unmarked \et{i.e.} for these vertices, $R[i]$ is now 1. \br%

            Also, for any edge $e = (u, v)$, we say that the edge $e$ is marked if $u$ is marked \et{i.e.} if $R[u] = 0$.

        \end{qsubsection}

        \begin{qsubsection}{Potential Function}

            We define the potential function to be $\phi = k_1 \para{\#(\text{marked edges})} + k_2 \para{\#(\text{number of edges}) - \#(\text{unmarked nodes})}$ where $k_1$ and $k_2$ are positive constants. \br%

            \note{For simplicity, we ignore the vertex $s$ when counting the unmarked nodes} \br%

            \begin{qproof}{$\phi$ is a valid potential function}

                Initially, when no edge has been inserted, the number of marked edges and total edges is 0. Also, since no vertex is reachable now (as we are excluding the vertex $s$), therefore, the initial value of the potential function is 0, as required. \br%

                Now, for the positivity of the potential function. Clearly, the number of marked edges can be only non-negative. Also, since for any vertex to be unmarked (excluding $s$), there must be at least one incident edge on this vertex. Hence, the number of edges is always greater than or equal to the number of unmarked nodes. Therefore, the potential function is always non-negative.

            \end{qproof}

            Since $\phi$ satisfies the properties of a valid potential function, it is a valid potential function.

        \end{qsubsection}

        \clearpage

        \begin{qsubsection}{Actual Cost}

            There are two cases, when the edge, say $(u, v)$ is inserted, either $v$ is marked or $v$ is unmarked.

            \begin{qcase}{1}{When the vertex $u$ is marked \et{i.e.} $R[u] = 0$}
                If the vertex $u$ is marked, from the algorithm, we can say, that the algorithm will stop at the first call, as it will not satisfy the outer `if' condition will return $false$. Hence this case will take only constant time, say $c_1$
            \end{qcase}

            \begin{qcase}{2}{When the vertex $u$ is unmarked \et{i.e} $R[u] = 1$}
                We will enter a recursion and will unmark all nodes which have not been unmarked yet and are reachable from this vertex. This is exactly doing DFS traversal over the nodes. \br%

                From this analogy, we can say that the time taken will be $\bigO{n + m}$. We can define $n$ to be the number of reachable and unmarked nodes from this vertex, and $m$ to be the number of edges in this subgraph and the number of out-edges in this subgraph to already unmarked nodes. This is essentially the sum of the outdegrees of all the nodes in this subgraph. \br%

                Since we are marking all visited nodes, we can reduce $n$ to be the number of nodes unmarked in this recursion. Therefore, $n = \,\#(\text{\et{nodes unmarked in this insertion}})$. \br%

                Also, since $m$ is the sum of outdegrees. For each edge included in this, it was a marked edge, which is now unmarked, as the vertex from which this is outgoing is now unmarked. Hence, we can define $m = \,\#(\text{\et{edges unmarked in this insertion}})$ \br%

                Hence, the total complexity of this insertion is therefore $\bigO{\#(\text{nodes unmarked in this insertion}) + \,\#(\text{edges unmarked in this insertion})}$
            \end{qcase}

            From the algorithm, we can see that the complexity of Case 1 will be the coefficient of the second term in the complexity of the second case. If in the number of edges unmarked also includes an edge that has been inserted and unmarked immediately, we can say the complexity of both cases will be $c_2 \,\#(\text{\et{nodes unmarked in this insertion}}) + c_1 \,\#(\text{\et{edges unmarked in this insertion}})$

            Therefore, our actual cost is
            \[c_2 \,\#(\text{\et{nodes unmarked in this insertion}}) + c_1 \,\#(\text{\et{edges unmarked in this insertion}})\]

        \end{qsubsection}

        \begin{qsubsection}{Amortized Cost}

            We can easily analyse the amortized cost of two cases. Here, we assume that the edge is inserted from $u$ to $v$ \br%

            We can define the difference in the potential function
            \[\Delta \phi = k_2 - \para{k_1 \,\#(\text{\et{edges unmarked in this insertion}}) + k_2 \,\#(\text{\et{nodes unmarked in this iteration}})}\] \br%

            \begin{table}[h!]
                \centering
                \begin{tabular}{| X{5cm} | X{3cm} | X{3cm} | X{3cm} |}
                    \hline
                    \tb{Case}                                   & \tb{Actual Cost}  & $\mb{\Delta \phi}$            & \tb{Amortized Cost} \\
                    \hline
                    When the vertex $u$ is initially unmarked   & $c_1$             & $k_2$                         & $c_1 + c_2$ \\
                    \hline
                    When the vertex $u$ is initially marked     & $c_1 m + c_2 n$   & $k_2 - \para{k_1 m + k_2 n}$  & $c_2$ \\
                    \hline
                \end{tabular}
                \caption{Amortized Cost Table}
            \end{table}

            \note{For the following discussion, assume $n = \,\#(\text{\et{nodes unmarked in this insertion}})$ and $m = \,\#(\text{\et{edges unmarked in this insertion}})$} \br%

            \note{We have taken $k_1 = c_1$ and $k_2 = c_2$}

            Therefore, it is clear that the amortized cost if $\le c_1 + c_2$. Hence the amortized cost is $\bigO{1}$, which implies that the time for $n$ edge insertions is $\bigO{n}$.

        \end{qsubsection}

    \end{qsection}

\end{question}

\begin{question}

	Given a Fibonacci heap, the most fundamental property is that for a node $x$ of degree $k$, size of the tree rooted at $x$ is always $\Omega(a^k)$ or in other words the maximum degree of a tree in Fibonacci heap of size n is $\O(\log n)$. \br%

	All the bounds discussed in class were based on this property of Fibonacci Heap. All the bounds in the original discussion would therefore hold if we prove that this property holds for the modified problem as well. \br%

	\begin{qproof}{Given a Fibonacci heap, if the subtree rooted at marked node v is cut from its parent and added to the root list only when it loses its third child, the bound on $size(x)$ for a node of degree k is $\Omega(a^k)$ always}

		Let us consider the children of the node x, $(v_1, v_2, v_3, \ldots, v_k)$ such that they are ordered in the increasing order of time of becoming children of the npde x. At the time when a child $v_i$ is added, for $i \geq 2$, $deg(v_i) \geq i-1$ as $deg(x) \geq i-1$. At the given instant, since $v_i$ is still a child of the node $x$, therefore it could have lost atmost 2 children. Therefore, currently $deg(v_i) \geq i-3$

	\begin{align*}
		s_k &\ = \text{minimum size of tree rooted at node of degree k} \\
		s_0 &\ = 1 \\
		s_k &\ \geq 1 + 1 + 1 + \sum_{i=3}^ks_{i-3} \\
		&\ \geq 3 + \sum_{i=0}^{k-3}s_i \\
		&\ \geq 3 + \sum_{i=0}^{k-4}s_i + s_{k-3} \\
		&\ \geq s_{k-1} + s_{k-3} \\
	\end{align*}

	Now we try to get a bound on $s_k$ by trying to get a bound on the following recurrence \br%

	\begin{align}
		f_n &= f_{n-1} + f_{n-3}
	\end{align} \br%

	We now try to prove that $f_n$ is bounded by $(\sqrt{2})^n$.
	\clearpage

	\begin{qproof}{The recurrence given by (1) is bounded such that $f_n \geq c^n$ for $n \geq 2$ where $c = \sqrt{2}$}
		We prove this using induction \br%

		\note{We only need to find one c} \br%

		\textbf{Base Case:} For $f_1 = 1$, $f_2 = 2$ and $f_3 = 3$. Therefore, the bound is true trivially for $n = 2, 3$. \br%

		\textbf{Induction Hypothesis:} If the bound holds true for all $i$ such that $i \leq n$, then it holds true for $n+1$ as well for $n \geq 2$. \br%

		\textbf{Induction step:}
		\begin{align*}
			f_{n+1}	&\eq	f_n + f_{n-2} \\
					&\qge	c^n + c^{n-2} \\
					&\eq	(c)^{n-2} \cdot (1 + c^2) \\
					&\qge c^{n+1} \eq (\sqrt{2})^{n + 1}
		\end{align*}

		Therefore, the induction step holds and hence the bound holds.

	\end{qproof}

	Also given that $s_k \geq f_k \geq 2^k$, therefore our original claim holds. This proves that the bounds persist even in the modified form of decrease-key and other operations.

	\end{qproof}

	Hence, we can say that the fibonacci heap will still hold.


\end{question}

\end{document}

